[
	{
		"category": ["ai", "agent"],
		"title": "AnalogCoder: Analog Circuit Design via Training-Free Code Generation",
		"authors": "Yao Lai, Sungyoung Lee, Guojin Chen, Souradip Poddar, Mengkang Hu, David Z. Pan, Ping Luo",
		"url": {
			"arxiv": "https://arxiv.org/abs/2405.14918"
		},
		"org": "The University of Hong Kong, The University of Texas at Austin, The Chinese University of Hong Kong",
		"date": "23-May-2024",
		"last_revised": "30-May-2024"
	},
	{
		"id": "multiagent-finetuning",
		"category": ["ai", "agent"],
		"title": "Multiagent Finetuning: Self Improvement with Diverse Reasoning Chains",
		"authors": "Vighnesh Subramaniam, Yilun Du, Joshua B. Tenenbaum, Antonio Torralba, Shuang Li, Igor Mordatch",
		"url": {
			"arxiv": "https://arxiv.org/abs/2501.05707"
		},
		"org": "MIT &amp; Google",
		"date": "10-Jan-2025"
	},
	{
		"id": "agents-are-not-enough",
		"category": ["ai", "agent"],
		"title": "Agents Are Not Enough",
		"authors": "Chirag Shah, Ryen W. White",
		"url": {
			"arxiv": "https://www.arxiv.org/abs/2412.16241"
		},
		"org": "University of Washington &amp; Microsoft Research",
		"date": "19-Dec-2024"
	},
	{
		"category": ["ai", "agent"],
		"title": "MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering",
		"authors": "Jun Shern Chan, Neil Chowdhury, Oliver Jaffe, James Aung, Dane Sherburn, Evan Mays, Giulio Starace, Kevin Liu, Leon Maksin, Tejal Patwardhan, Lilian Weng, Aleksander Mądry",
		"url": {
			"arxiv": "https://arxiv.org/abs/2410.07095"
		},
		"org": "OpenAI",
		"date": "09-Oct-2024",
		"last_revised": "24-Oct-2024"
	},
	{
		"category": ["ai", "agent"],
		"title": "Agent-as-a-Judge: Evaluate Agents with Agents",
		"authors": "Mingchen Zhuge, Changsheng Zhao, Dylan Ashley, Wenyi Wang, Dmitrii Khizbullin, Yunyang Xiong, Zechun Liu, Ernie Chang, Raghuraman Krishnamoorthi, Yuandong Tian, Yangyang Shi, Vikas Chandra, Jürgen Schmidhuber",
		"url": {
			"arxiv": "https://arxiv.org/abs/2410.10934"
		},
		"org": "Meta AI, King Abdullah University of Science and Technology (KAUST)",
		"date": "14-Oct-2024",
		"last_revised": "16-Oct-2024"
	},
	{
		"category": ["ai", "agent"],
		"title": "MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains",
		"authors": "Guoli Yin, Haoping Bai, Shuang Ma, Feng Nan, Yanchao Sun, Zhaoyang Xu, Shen Ma, Jiarui Lu, Xiang Kong, Aonan Zhang, Dian Ang Yap, Yizhe zhang, Karsten Ahnert, Vik Kamath, Mathias Berglund, Dominic Walsh, Tobias Gindele, Juergen Wiest, Zhengfeng Lai, Xiaoming Wang, Jiulong Shan, Meng Cao, Ruoming Pang, Zirui Wang",
		"url": {
			"arxiv": "https://arxiv.org/abs/2407.18961"
		},
		"org": "Apple Inc.",
		"date": "18-Jul-2024",
		"last_revised": "15-Aug-2024"
	},
	{
		"category": ["optimization"],
		"title": "Model-Based Deep Learning: On the Intersection of Deep Learning and Optimization",
		"authors": "N. Schlezinger, Y. Eldar, S. Boyd",
		"journal": "IEEE Access",
		"url": {
			"Boyd's homepage": "https://stanford.edu/~boyd/papers/model_based_deep_learning.html",
			"arxiv": "https://arxiv.org/abs/2205.02640"
		},
		"date": "05-May-2022",
		"last_revised": "21-Jun-2022"
	},
	{
		"category": ["optimization"],
		"title": "Compact Model Parameter Extraction via Derivative-Free Optimization",
		"authors": "Rafael Perez Martinez, Masaya Iwamoto, Kelly Woo, Zhengliang Bian, Roberto Tinti, Stephen Boyd, Srabanti Chowdhury",
		"journal": "IEEE Access",
		"url": {
			"Boyd's homepage": "https://stanford.edu/~boyd/papers/compact_model_parameter_extraction.html",
			"arxiv": "https://arxiv.org/abs/2406.16355"
		},
		"date": "24-Jun-2024",
		"last_revised": "11-Nov-2024"
	},
	{
		"category": ["optimization"],
		"title": "A Heuristic for Optimizing Stochastic Activity Networks with Applications to Statistical Digital Circuit Sizing",
		"authors": "S.-J. Kim, S. Boyd, S. Yun, D. Patil, M. Horowitz",
		"journal": "Optimization and Engineering",
		"url": {
			"Boyd's homepage": "https://stanford.edu/~boyd/papers/heur_san_opt.html",
			"Springer": "https://link.springer.com/article/10.1007/s11081-007-9011-5"
		},
		"date": "01-Dec-2007"
	},
	{
		"category": ["optimization", "cvxopt"],
		"title": "A Distributed Method for Fitting Laplacian Regularized Stratified Models",
		"authors": "J. Tuck, S. Barratt, S. Boyd",
		"journal": "Journal of Machine Learning Research",
		"url": {
			"Boyd's homepage": "https://stanford.edu/~boyd/papers/strat_models.html",
			"arxiv": "https://arxiv.org/abs/1904.12017"
		},
		"date": "26-Apr-2019",
		"last_revised": "10-Nov-2019"
	},
	{
		"id": "opt-via-circuits",
		"category": ["optimization", "cvxopt"],
		"title": "Optimization Algorithm Design via Electric Circuits",
		"authors": "Stephen P. Boyd, Tetiana Parshakova, Ernest K. Ryu, Jaewook J. Suh",
		"conference": "NeurIPS 2024",
		"url": {
			"Boyd's homepage": "https://stanford.edu/~boyd/papers/compact_model_parameter_extraction.html",
			"arxiv": "https://arxiv.org/abs/2411.02573"
		},
		"date": "04-Nov-2024"
	},
	{
		"category": ["optimization", "cvxopt"],
		"title": "Infeasibility Detection in the Alternating Direction Method of Multipliers for Convex Optimization",
		"authors": "G. Banjac, P. Goulart, B. Stellato, S. Boyd",
		"journal": "Journal of Optimization Theory and Applications",
		"url": {
			"Boyd's homepage": "https://stanford.edu/~boyd/papers/admm_infeas.html",
			"IEEE": "https://ieeexplore.ieee.org/document/8516858"
		},
		"date": "01-Sep-2018"
	},
	{
		"category": ["optimization", "cvxopt"],
		"title": "Distributed Majorization-Minimization for Laplacian Regularized Problems",
		"authors": "J. Tuck, D. Hallac, S. Boyd",
		"journal": "IEEE-CAA Journal of Automatica Sinica",
		"url": {
			"Boyd's homepage": "https://stanford.edu/~boyd/papers/mm_dist_lapl.html",
			"arxiv": "https://arxiv.org/abs/1803.10317"
		},
		"date": "27-Mar-2018",
		"last_revised": "30-Mar-2018"
	},
	{
		"category": ["optimization", "cvxopt"],
		"title": "Multi-Period Trading via Convex Optimization",
		"authors": "S. Boyd, E. Busseti, S. Diamond, R. Kahn, K. Koh, P. Nystrup, J. Speth",
		"journal": "Foundations and Trends in Optimization",
		"url": {
			"Boyd's homepage": "https://stanford.edu/~boyd/papers/cvx_portfolio.html",
			"arxiv": "https://arxiv.org/abs/1705.00109"
		},
		"date": "01-Aug-2017"
	},
	{
		"category": ["optimization", "cvxopt"],
		"title": "Matrix-Free Convex Optimization Modeling",
		"authors": "S. Diamond and S. Boyd",
		"journal": "Optimization and Its Applications in Control and Data Sciences",
		"url": {
			"Boyd's homepage": "https://stanford.edu/~boyd/papers/abs_ops.html",
			"arxiv": "https://arxiv.org/abs/1506.00760"
		},
		"date": "01-Jan-2016"
	},
	{
		"category": ["optimization", "cvxopt"],
		"title": "Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers",
		"authors": "S. Boyd, N. Parikh, E. Chu, B. Peleato, J. Eckstein",
		"journal": "Foundations and Trends in Machine Learning",
		"url": {
			"Boyd's homepage": "https://stanford.edu/~boyd/papers/admm_distr_stats.html",
			"arxiv": "https://ieeexplore.ieee.org/document/8186925"
		},
		"date": "01-Jan-2011"
	},
	{
		"category": ["optimization", "cvxopt"],
		"title": "A New Method for Design of Robust Digital Circuits",
		"authors": "D. Patil, S. Yun, S.-J. Kim, A. Cheung, M. Horowitz, S. Boyd",
		"conference": "International Symposium on Quality Electronic Design (ISQED) 2005",
		"url": {
			"Boyd's homepage": "https://stanford.edu/~boyd/papers/isqed05.html",
			"IEEE": "https://ieeexplore.ieee.org/document/1410662"
		},
		"date": "01-Mar-2005"
	},
	{
		"category": ["optimization", "cvxopt"],
		"title": "Design of robust global power and ground networks",
		"authors": "S. Boyd, L. Vandenberghe, A. El Gamal, S. Yun",
		"conference": "ACM/SIGDA Symposium on Physical Design (ISPD) 2001",
		"url": {
			"Boyd's homepage": "https://stanford.edu/~boyd/papers/rob_glob_pg.html",
			"ACM": "https://dl.acm.org/doi/10.1145/369691.369734"
		},
		"date": "01-Apr-2001"
	},
	{
		"category": ["ai", "metric learning"],
		"title": "Self-Taught Metric Learning without Labels",
		"authors": "Sungyeon Kim, Dongwon Kim, Minsu Cho, Suha Kwak",
		"org": "POSTECH",
		"url": {
			"arxiv": "https://arxiv.org/abs/2205.01903",
			"github": "https://github.com/tjddus9597/STML-CVPR22",
			"ResearchGate": "https://www.researchgate.net/publication/363906881_Self-Taught_Metric_Learning_without_Labels"
		},
		"date": "04-May-2022"
	},
	{
		"category": ["ai", "metric learning"],
		"title": "A Robust and Efficient Doubly Regularized Metric Learning Approach",
		"authors": "Meizhu Liu, Baba C. Vemuri",
		"url": {
			"academia.edu": "https://www.academia.edu/77676366/A_Robust_and_Efficient_Doubly_Regularized_Metric_Learning_Approach",
			"NIH": "https://pmc.ncbi.nlm.nih.gov/articles/PMC3761969/"
		},
		"date": "01-Jan-2012"
	},
	{
		"category": ["code repo", "ai"],
		"title": "OpenAI's Swarm",
		"authors": "OpenAI",
		"url": {
			"github": "https://github.com/openai/swarm"
		},
		"date": "10-Oct-2024"
	},
	{
		"category": ["ai", "bio"],
		"title": "Sequence modeling and design from molecular to genome scale with Evo",
		"authors": "Eric Nguyen, Michael Poli, Matthew G. Durrant, Brian Kang, Dhruva Katrekar, David B. Li, Liam J. Bartie, Armin W. Thomas, Samuel H. King, Garyk Brixi, Jeremy Sullivan, Madelena Y. Ng, Ashley Lewis, Aaron Lou, Stefano Ermon, Stephen A. Baccus, Tina Hernandez-Boussard, Christopher Ré, Patrick D. Hsu, Brian L. Hie",
		"org": "Arc Institute, Department of Computer Science @ Stanford University, Stanford Data Science",
		"url": {
			"Science": "https://www.science.org/doi/10.1126/science.ado9336"
		},
		"date": "15-Nov-2024"
	},
	{
		"category": ["ai", "bio"],
		"title": "Predicting Gene Ontology Annotations from CAFA Using Distance Machine Learning and Transfer Metric Learning",
		"authors": "Shilpa Choudhary, MD Khaja Shaik, Sivaneasan Bala Krishnan, Sunita Gupta",
		"url": {
			"Wiley": "https://onlinelibrary.wiley.com/doi/abs/10.1002/9781394268832.ch21"
		},
		"date": "30-Sep-2024"
	},
	{
		"category": ["ai", "fundamentals"],
		"title": "Classification is a Strong Baseline for Deep Metric Learning",
		"authors": "Andrew Zhai, Hao-Yu Wu",
		"url": {
			"arxiv": "https://arxiv.org/abs/1811.12649"
		},
		"date": "30-Nov-2018"
	},
	{
		"category": ["ai", "bio"],
		"title": "Geometry-Aware Generative Autoencoders for Warped Riemannian Metric Learning and Generative Modeling on Data Manifolds",
		"authors": "Xingzhi Sun, Danqi Liao, Kincaid MacDonald, Yanlei Zhang, Chen Liu, Guillaume Huguet, Guy Wolf, Ian Adelstein, Tim G. J. Rudner, Smita Krishnaswamy",
		"url": {
			"arxiv": "https://arxiv.org/abs/2410.12779"
		},
		"date": "16-Oct-2024",
		"postfix": [
			"&nbsp;",
			"<div class=\"foldable-toggle\">abstract</div>",
			"<div class=\"foldable-content\">",
			"<p>",
			"Rapid growth of high-dimensional datasets in fields such as single-cell RNA sequencing and spatial genomics has led to unprecedented opportunities for scientific discovery, but it also presents unique computational and statistical challenges. Traditional methods struggle with geometry-aware data generation, interpolation along meaningful trajectories, and transporting populations via feasible paths. To address these issues, we introduce Geometry-Aware Generative Autoencoder (GAGA), a novel framework that combines extensible manifold learning with generative modeling. GAGA constructs a neural network embedding space that respects the intrinsic geometries discovered by manifold learning and learns a novel warped Riemannian metric on the data space. This warped metric is derived from both the points on the data manifold and negative samples off the manifold, allowing it to characterize a meaningful geometry across the entire latent space. Using this metric, GAGA can uniformly sample points on the manifold, generate points along geodesics, and interpolate between populations across the learned manifold using geodesic-guided flows. GAGA shows competitive performance in simulated and real-world datasets, including a 30% improvement over the state-of-the-art methods in single-cell population-level trajectory inference.",
			"</p>",
			"</div>"
		]
	},
	{
		"category": ["ai", "fundamentals"],
		"title": "How Classification Baseline Works for Deep Metric Learning: A Perspective of Metric Space",
		"authors": "Yuanqu Mou, Zhengxue Jian, Haiyang Bai, Chang Gou",
		"url": {
			"OpenReview.net": "https://openreview.net/forum?id=DVl5GAuBXA"
		},
		"date": "05-Sep-2024",
		"postfix": [
			"&nbsp;",
			"<div class=\"foldable-toggle\">abstract</div>",
			"<div class=\"foldable-content\">",
			"<p>",
			"Deep Metric Learning (DML) stands as a powerful technique utilized for training models to capture semantic similarities between data points across various domains, including computer vision, natural language processing, and recommendation systems. Current approaches in DML often prioritize the development of novel network structures or loss functions while overlooking metric properties and the intricate relationship between classification and metric learning. This oversight results in significant time overhead, particularly when the number of categories increases. To address this challenge, we propose extending the loss function used in classification to function as a metric, thereby imposing constraints on the distances between training samples based on the triangle inequality. This approach is akin to proxy-based methods and aims to enhance the efficiency of DML. Drawing inspiration from metrically convex metrics, we introduce the concept of a \"weak-metric\" to overcome the limitations associated with certain loss functions that cannot be straightforwardly extended to full metrics. This ensures the effectiveness of DML under various circumstances. Furthermore, we extend the Cross Entropy loss function to function as a weak-metric and introduce a novel metric loss derived from Cross Entropy for experimental comparisons with other methods. The results underscore the credibility and reliability of our proposal, showcasing its superiority over state-of-the-art techniques. Notably, our approach also exhibits significantly faster training times as the number of categories increases, making it a compelling choice for large-scale datasets.",
			"</p>",
			"</div>"
		]
	},
	{
		"category": ["ai", "nn-models"],
		"title": "Statistical Mechanics of Neural Networks",
		"authors": "Haim Sompolinsky",
		"url": {
			"Physics Today": "https://lnkd.in/gjRQWUb9"
		},
		"date": "01-Dec-1988",
		"postfix": [
			"(Haim Sompolinsky is a professor of physics at the Racah\nInstitute of Physics of the Hebrew University of Jerusalem.)"
		]

	},
	{
		"category": ["ai", "dl-models"],
		"title": "Generating Sentences from a Continuous Space",
		"date": "19-Nov-2015",
		"url": {
			"arxiv": "https://arxiv.org/abs/1511.06349"
		}
	},
	{
		"category": ["ai", "dl-models"],
		"title": "Improved Variational Autoencoders for Text Modeling using Dilated Convolutions",
		"date": "27-Feb-2017",
		"url": {
			"arxiv": "https://arxiv.org/abs/1702.08139"
		}
	},
	{
		"category": ["ai", "dl-models"],
		"title": "Robust flight navigation out of distribution with liquid neural networks",
		"date": "19-Apr-2023",
		"url": {
			"ScienceRobotics": "https://www.science.org/doi/10.1126/scirobotics.adc8892"
			}
	},
	{
		"id": "attention-is-all-you-need",
		"category": ["ai", "llm"],
		"title": "Attention Is All You Need",
		"authors": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin",
		"date": "12-Jun-2017",
		"last_revised": "02-Aug-2023",
		"org": "Google Brain, Google Research",
		"url": {
			"arxiv": "https://arxiv.org/abs/1706.03762"
		}
	},
	{
		"id": "llm-titans",
		"category": ["ai", "llm"],
		"title": "Titans: Learning to Memorize at Test Time",
		"authors": "Ali Behrouz, Peilin Zhong, Vahab Mirrokni",
		"date": "31-Dec-2024",
		"org": "Google Research",
		"url": {
			"arxiv": "https://arxiv.org/abs/2501.00663"
		}
	},
	{
		"category": ["ai", "llm"],
		"title": "Foundations of Large Language Models",
		"authors": "Tong Xiao, Jingbo Zhu",
		"date": "16-Jan-2025",
		"org": "NLP Lab, Northeastern University &amp; NiuTrans Research",
		"url": {
			"arxiv": "https://arxiv.org/abs/2501.09223"
		}
	},
	{
		"category": ["ai", "llm"],
		"title": "HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge in RAG Systems",
		"authors": "Jiejun Tan, Zhicheng Dou, Wen Wang, Mang Wang, Weipeng Chen, Ji-Rong Wen",
		"date": "05-Nov-2024",
		"org": "Renmin University of China, Baichuan Intelligent Technology",
		"url": {
			"arxiv": "https://arxiv.org/abs/2411.02959v1"
		}
	},
	{
		"category": ["ai", "llm"],
		"title": "SWE-bench: Can Language Models Resolve Real-World GitHub Issues?",
		"date": "10-Oct-2023",
		"url": {
			"arxiv": "https://arxiv.org/abs/2310.06770"
		},
		"authors": "Carlos E. Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, Karthik Narasimhan",
		"org": "Princeton University, Princeton Language and Intelligence, University of Chicago",
		"postfix": [
			"&nbsp;",
			"<div class=\"foldable-toggle\">RAG pipeline for Chatbots</div>",
			"<div class=\"foldable-content\">",
			"<div class=\"fig-container\">",
			"<figure>",
			"<img src=\"/assets/images/ai/llm/rag-pipeline-for-chatbot-nvidia.png\">",
			"<figcaption>",
			"Control Points in a typical RAG pipeline when building Chatbots",
			"</figcaption>",
			"</figure>",
			"</div>",
			"</div>"
		]
	},
	{
		"id": "facts",
		"category": ["ai", "llm"],
		"title": "FACTS About Building Retrieval Augmented Generation-based Chatbots",
		"date": "10-Jul-2024",
		"url": {
			"arxiv": "https://arxiv.org/abs/2407.07858"
		},
		"authors": "Rama Akkiraju, Anbang Xu, Deepak Bora, Tan Yu, Lu An, Vishal Seth, Aaditya Shukla, Pritam Gundecha, Hridhay Mehta, Ashwin Jha, Prithvi Raj, Abhinav Balasubramanian, Murali Maram, Guru Muthusamy, Shivakesh Reddy Annepally, Sidney Knowles, Min Du, Nick Burnett, Sean Javiya, Ashok Marannan, Mamta Kumari, Surbhi Jha, Ethan Dereszenski, Anupam Chakraborty, Subhash Ranjan, Amina Terfai, Anoop Surya, Tracey Mercer, Vinodh Kumar Thanigachalam, Tamar Bar, Sanjana Krishnan, Samy Kilaru, Jasmine Jaksic, Nave Algarici, Jacob Liberman, Joey Conway, Sonu Nayyar, Justin Boitano",
		"org": "NVIDIA",
		"postfix": [
			"&nbsp;",
			"<div class=\"foldable-toggle\">RAG pipeline for Chatbots</div>",
			"<div class=\"foldable-content\">",
			"<div class=\"fig-container\">",
			"<figure>",
			"<img src=\"/assets/images/ai/llm/rag-pipeline-for-chatbot-nvidia.png\">",
			"<figcaption>",
			"Control Points in a typical RAG pipeline when building Chatbots",
			"</figcaption>",
			"</figure>",
			"</div>",
			"</div>"
		]
	},
	{
		"category": ["ai", "llm"],
		"title": "To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning arxiv",
		"date": "18-Sep-2024",
		"url": {
			"arxiv": "https://arxiv.org/abs/2409.12183"
		},
		"postfix": [
			"&nbsp;",
			"<div class=\"foldable-toggle\">abstract</div>",
			"<div class=\"foldable-content\">",
			"<p>",
			"Chain-of-thought (CoT) via prompting is the de facto method",
			" for eliciting reasoning capabilities from large language models (LLMs).",
			" But for what kinds of tasks is this extra \"thinking\" really helpful?",
			" To analyze this, we conducted a quantitative meta-analysis covering over 100 papers",
			" using CoT and ran our own evaluations of 20 datasets across 14 models.",
			" Our results show that CoT gives strong performance benefits primarily",
			" on tasks involving math or logic, with much smaller gains on other types of tasks.",
			" On MMLU, directly generating the answer without CoT leads",
			" to almost identical accuracy as CoT unless the question or model's response",
			" contains an equals sign, indicating symbolic operations and reasoning.",
			" Following this finding, we analyze the behavior of CoT on these problems",
			" by separating planning and execution and comparing against tool-augmented LLMs.",
			" Much of CoT's gain comes from improving symbolic execution,",
			" but it underperforms relative to using a symbolic solver.",
			" Our results indicate that CoT can be applied selectively,",
			" maintaining performance while saving inference costs.",
			" Furthermore, they suggest a need to move beyond prompt-based CoT to new paradigms",
			" that better leverage intermediate computation",
			" across the whole range of LLM applications.",
			"</p>",
			"</div>"
		]
	},
	{
		"category": ["ai", "llm"],
		"title": "OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs arxiv",
		"date": "08-Sep-2024",
		"url": {
			"arxiv": "https://arxiv.org/abs/2409.05152"
		}
	},
	{
		"category": ["ai", "llm"],
		"title": "Distilling System 2 into System 1",
		"authors": "Ping Yu, Jing Xu, Jason Weston, Ilia Kulikov",
		"org": "META Fair",
		"date": "24-Jul-2024",
		"url": {
			"arxiv": "https://arxiv.org/abs/2407.06023"
		}
	},
	{
		"category": ["ai", "llm"],
		"title": "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation",
		"authors": "Tu Vu, Kalpesh Krishna, Salaheddin Alzubi, Chris Tar, Manaal Faruqui, Yun-Hsuan Sung",
		"org": "Google, Google DeepMind &amp; UMass Amherst",
		"date": "15-Jul-2024",
		"url": {
			"arxiv": "https://arxiv.org/abs/2407.10817"
		}
	},
	{
		"id": "unreasonable-effectiveness-of-data",
		"category": ["ai", "llm-intelligence"],
		"title": "The Unreasonable Effectiveness of Data",
		"authors": "Alon Halevy, Peter Norvig, Fernando Pereira",
		"date": "24-Mar-2009",
		"org": "Google",
		"url": {
			"Google Research": "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35179.pdf"
		}
	},
	{
		"category": ["ai", "llm-intelligence"],
		"title": "Simulacra as Conscious Exotica",
		"date": "19-Feb-2012",
		"authors": "Murray Shanahan",
		"url": {
			"arxiv": "https://arxiv.org/abs/2402.12422"
		}
	},
	{
		"category": ["ai", "llm-intelligence"],
		"title": "Satori Before Singularity",
		"date": "01-Jan-2012",
		"authors": "Murray Shanahan",
		"url": {
			"PDF": "https://www.doc.ic.ac.uk/~mpsha/ShanahanJCS2012.pdf"
		}
	},
	{
		"category": ["ai", "llm-intelligence"],
		"title": "Talking About Large Language Models",
		"date": "07-Dec-2022",
		"authors": "Murray Shanahan",
		"url": {
			"arxiv": "https://arxiv.org/abs/2212.03551"
		}
	},
	{
		"category": ["ai", "slm"],
		"title": "Mistral AI Released Mistral-Small-Instruct-2409: A Game-Changing Open-Source Language Model Empowering Versatile AI Applications with Unmatched Efficiency and Accessibility",
		"date": "18-Sep-2024",
		"url": {
			"MarkTechPost": "https://www.marktechpost.com/2024/09/18/mistral-ai-released-mistral-small-instruct-2409-a-game-changing-open-source-language-model-empowering-versatile-ai-applications-with-unmatched-efficiency-and-accessibility/?amp",
			"model card": "https://huggingface.co/mistralai/Mistral-Small-Instruct-2409"
		}
	},
	{
		"category": ["ai", "cv"],
		"title": "Mask2Map: Vectorized HD Map Construction Using Bird's Eye View Segmentation Masks",
		"authors": "Sehwan Choi, Jungho Kim, Hongjae Shin, Jun Won Choi",
		"org": "Hanyang University, SNU",
		"date": "18-Jul-2024",
		"url": {
			"arxiv": "https://arxiv.org/abs/2407.13517"
		}
	},
	{
		"category": ["ai", "recsys"],
		"title": "Collaborative Filtering for Implicit Feedback Datasets",
		"authors": "Yifan Hu, Yehuda Koren, Chris Volinsky",
		"org": "AT&amp;T Labs, Yahoo! Research",
		"date": "18-Jul-2024",
		"url": {
			"PDF": "http://yifanhu.net/PUB/cf.pdf"
		}
	},
	{
		"category": ["ai", "recsys"],
		"title": "Applications of the conjugate gradient method for implicit feedback collaborative filtering",
		"authors": "Gábor Takács, István Pilászy, Domonkos Tikk",
		"date": "23-Oct-2011",
		"url": {
			"ACM": "https://dl.acm.org/doi/10.1145/2043932.2043987",
			"PDF": "/resource/papers/Applications of the Conjugate Gradient Method for Implicit Feedback Collaborative Filtering.pdf"
		}
	},
	{
		"category": ["ai", "recsys"],
		"title": "BPR: Bayesian Personalized Ranking from Implicit Feedback",
		"authors": "Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, Lars Schmidt-Thieme",
		"date": "09-May-2012",
		"url": {
			"arxiv": "https://arxiv.org/abs/1205.2618"
		}
	},
	{
		"category": ["ai", "recsys"],
		"title": "Logistic Matrix Factorization for Implicit Feedback Data",
		"authors": "Christopher C. Johnson",
		"org": "Spotify",
		"date": "01-Dec-2014",
		"url": {
			"PDF": "https://stanford.edu/~rezab/nips2014workshop/submits/logmat.pdf"
		}
	}
]